{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import glob\n",
    "\n",
    "from mitie import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading NER Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ner = named_entity_extractor('./MITIE-models/english/ner_model.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data_test_coreference.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 164\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "#Convert dataset to tokens\n",
    "titles = []\n",
    "facts = []\n",
    "number = len(dataset)\n",
    "print('Size:', number)\n",
    "for idx in range(number):\n",
    "    print(idx)\n",
    "    content = \"\"\n",
    "    content = dataset[\"Content\"].values[idx]\n",
    "    title = dataset[\"Content\"].index[idx]\n",
    "    tokens = tokenize(content)\n",
    "    #Get entities from tokens\n",
    "    # entities is a list of tuples, each containing an xrange that indicates which\n",
    "    # tokens are part of the entity, the entity tag, and an associate score.  The\n",
    "    # entities are also listed in the order they appear in the input text file.\n",
    "    # Here we just print the score, tag, and text for each entity to the screen.\n",
    "    # The larger the score the more confident MITIE is in its prediction.\n",
    "    entities = ner.extract_entities(tokens)\n",
    "    # Now let's run one of MITIE's binary relation detectors.  MITIE comes with a\n",
    "    # bunch of different types of relation detector and includes tools allowing you\n",
    "    # to train new detectors.  However, here we simply use one, the \"person born in\n",
    "    # place\" relation detector.\n",
    "    rel_classifier_names = glob.glob(\"./MITIE-models/english/binary_relations/*.svm\")\n",
    "    for rel_classifier_name in rel_classifier_names:\n",
    "        rel_detector = binary_relation_detector(rel_classifier_name)\n",
    "        relation_type = rel_classifier_name.split(\".\")[-2]\n",
    "        # First, let's make a list of neighboring entities.  Once we have this list we\n",
    "        # will ask the relation detector if any of these entity pairs is an example of\n",
    "        # the \"person born in place\" relation.\n",
    "        neighboring_entities = [(entities[i][0], entities[i+1][0]) for i in xrange(len(entities)-1)]\n",
    "        # Also swap the entities and add those in as well.  We do this because \"person\n",
    "        # born in place\" mentions can appear in the text in as \"place is birthplace of\n",
    "        # person\".  So we must consider both possible orderings of the arguments.\n",
    "        neighboring_entities += [(r,l) for (l,r) in neighboring_entities]\n",
    "        # Now that we have our list, let's check each entity pair and see which one the\n",
    "        # detector selects.\n",
    "        for first_entity, second_entity in neighboring_entities:\n",
    "            fact = []\n",
    "            # Detection has two steps in MITIE. First, you convert a pair of entities\n",
    "            # into a special representation.\n",
    "            rel = ner.extract_binary_relation(tokens, first_entity, second_entity)\n",
    "            # Then you ask the detector to classify that pair of entities.  If the\n",
    "            # score value is > 0 then it is saying that it has found a relation.  The\n",
    "            # larger the score the more confident it is.  Finally, the reason we do\n",
    "            # detection in two parts is so you can reuse the intermediate rel in many\n",
    "            # calls to different relation detectors without needing to redo the\n",
    "            # processing done in extract_binary_relation().\n",
    "            score = rel_detector(rel)\n",
    "            # Print out any matching relations.\n",
    "            if (score > 0.5):\n",
    "                first_entity_text     = \" \".join(tokens[i].decode(\"utf-8\")  for i in first_entity)\n",
    "                second_entity_text = \" \".join(tokens[i].decode(\"utf-8\")  for i in second_entity)\n",
    "                fact.append(first_entity_text)\n",
    "                fact.append(relation_type)\n",
    "                fact.append(second_entity_text)\n",
    "                facts.append(fact)\n",
    "                titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_to_n = {}\n",
    "n_to_t = {}\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    n_to_t[i] = dataset.iloc[i, ]\n",
    "    t_to_n[dataset.iloc[i, 0]] = i\n",
    "\n",
    "facts_numpy = np.array(facts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {}\n",
    "dd['entity1'] = facts_numpy[:, 0].tolist()\n",
    "dd['relation'] = facts_numpy[:, 1].tolist()\n",
    "dd['entity2'] = facts_numpy[:, 2].tolist()\n",
    "dd['id_article'] = [t_to_n[x]+1 for x in titles]\n",
    "dd['article'] = titles\n",
    "ner_data_frame = pd.DataFrame(data=dd)\n",
    "ner_data_frame = ner_data_frame[['id_article', 'article', 'entity1', 'relation', 'entity2']]\n",
    "ner_data_frame.to_csv('mitie_content_coref_0.5.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
